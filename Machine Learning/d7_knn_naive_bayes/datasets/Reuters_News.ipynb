{"cells":[{"cell_type":"markdown","source":"<!--NAVIGATION-->\n\n<a href=\"https://colab.research.google.com/github/bpesquet/machine-learning-katas/blob/master/classic-datasets/Reuters_News.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a>\n","metadata":{"cell_id":"00000-629c6a94-3189-4110-a633-fd2c5ccc5a37","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"# Kata: Reuters News Dataset\n\n| Learning type | Activity type | Objective |\n| - | - | - |\n| Supervised | Multiclass classification | Classify news articles by their topic |","metadata":{"cell_id":"00001-2f270c54-8e62-4fd0-80cf-4406d4228016","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## Instructions\n\nThis is a self-correcting exercise generated by [nbgrader](https://github.com/jupyter/nbgrader). \n\nComplete the cells beginning with `# YOUR CODE HERE` and run the subsequent cells to check your code.","metadata":{"cell_id":"00002-3837570a-327a-4703-97af-fc48fd3e0d50","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## About the dataset\n\nThe [Reuters](https://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection) dataset is a set of short newswires and their topics, published by Reuters in 1987 and widely used for text classification. There are 46 different topics, some more represented than others. These topics are mutually exclusive: a news can only belong to one topic.\n\n![Reuters logo](images/Reuters-logo.png)","metadata":{"cell_id":"00003-64883e69-068b-4711-8bf0-1157dfbcc2c9","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## Package setup","metadata":{"cell_id":"00004-f246764d-ed63-46dd-aa0c-03af184a3687","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### Question\n\nLoad and setup the appropriate Python packages.","metadata":{"cell_id":"00005-ed055ce2-d5fa-4780-9503-8c994c6b3f77","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"85576880b4373a61c7301f80056d66f1","grade":false,"grade_id":"cell-7f538d5d9435b483","locked":false,"schema_version":1,"solution":true},"cell_id":"00006-8179756e-9a6f-4b67-a475-26d67f7c3999","deepnote_cell_type":"code"},"source":"# YOUR CODE HERE","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utility functions","metadata":{"cell_id":"00007-8a151a70-af24-45d0-8fde-bae90c70b603","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"f968ca3dda64065db1b527bff4a42901","grade":false,"grade_id":"cell-601e75bf5f06e927","locked":true,"schema_version":1,"solution":false},"cell_id":"00008-bbfe0a89-f35b-4504-8981-abbd2967dcc5","deepnote_cell_type":"code"},"source":"def plot_loss_acc(history):\n    \"\"\"Plot training and (optionally) validation loss and accuracy\"\"\"\n\n    loss = history.history['loss']\n    epochs = range(1, len(loss) + 1)\n\n    plt.figure(figsize=(10, 10))\n\n    plt.subplot(2, 1, 1)\n    plt.plot(epochs, loss, '.--', label='Training loss')\n    final_loss = loss[-1]\n    title = 'Training loss: {:.4f}'.format(final_loss)\n    plt.ylabel('Loss')\n    if 'val_loss' in history.history:\n        val_loss = history.history['val_loss']\n        plt.plot(epochs, val_loss, 'o-', label='Validation loss')\n        final_val_loss = val_loss[-1]\n        title += ', Validation loss: {:.4f}'.format(final_val_loss)\n    plt.title(title)\n    plt.legend()\n\n    acc = history.history['acc']\n\n    plt.subplot(2, 1, 2)\n    plt.plot(epochs, acc, '.--', label='Training acc')\n    final_acc = acc[-1]\n    title = 'Training accuracy: {:.2f}%'.format(final_acc * 100)\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    if 'val_acc' in history.history:\n        val_acc = history.history['val_acc']\n        plt.plot(epochs, val_acc, 'o-', label='Validation acc')\n        final_val_acc = val_acc[-1]\n        title += ', Validation accuracy: {:.2f}%'.format(final_val_acc * 100)\n    plt.title(title)\n    plt.legend()\n    \n\ndef vectorize_sequences(sequences, dimension=10000):\n    \"\"\"One-hot encode a vector of sequences into a binary matrix (number of sequences, dimension)\"\"\"\n    \n    # Example : [[3, 5]] -> [[0. 0. 0. 1. 0. 1. 0...]]\n    \n    results = np.zeros((len(sequences), dimension))\n    # set specific indices of results[i] to 1s\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1.\n    return results","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 1: Loading the data","metadata":{"cell_id":"00009-5eb30f4f-8f50-4087-b611-5a305a012afa","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### Question\n\n* Load the Reuters dataset included with Keras. Limit yourself to the 10,000 most frequent words.\n* Print shapes of training data and labels.\n* Print the first training sample.\n* Print the first 10 labels.","metadata":{"cell_id":"00010-5459f749-7272-4fe8-8ffc-18345b3e4b19","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"fa9525392f2f6a0dac812a32c516a311","grade":false,"grade_id":"cell-5e3ac2eb6ea86d5e","locked":false,"schema_version":1,"solution":true},"cell_id":"00011-42b795e0-6e1e-445d-9cbb-b3f8c6c72290","deepnote_cell_type":"code"},"source":"# YOUR CODE HERE","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"48609e7e57430b383681e199d77e1774","grade":false,"grade_id":"cell-3e125eb5fc73aba4","locked":true,"schema_version":1,"solution":false},"cell_id":"00012-9d729b8a-e115-4a9f-a730-cc78adb7dbc2","deepnote_cell_type":"code"},"source":"# Showing the first 10 samples as text\n\n# word_index is a dictionary mapping words to an integer index\nword_index = reuters.get_word_index()\n# We reverse it, mapping integer indices to words\nreverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n# We decode the news; note that our indices were offset by 3\n# because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\ndecoded_news = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\nprint(decoded_news)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 2: Preparing the data","metadata":{"cell_id":"00013-edf02ce8-508a-492a-b9ff-cedf1d5b4212","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### Question\n\nPrepare data for training. Set apart the first 1,000 examples for validation. Store the data subsets in variables named `x_train`/`y_train`, `x_val`/`y_val` and `x_test`/`y_test`.","metadata":{"cell_id":"00014-58ecf6c8-3539-481c-94d6-a836dbb69c5c","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"0284d14447cfa5239f7f9e2f6bee84a7","grade":false,"grade_id":"cell-772c636277b2a660","locked":false,"schema_version":1,"solution":true},"cell_id":"00015-b9081448-ad2a-4057-8aec-53df9cf0e095","deepnote_cell_type":"code"},"source":"# Turn news into vectors of 0s and 1s (one-hot encoding)\nx_train = vectorize_sequences(train_data)\nx_test = vectorize_sequences(test_data)\n\n# YOUR CODE HERE","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"7ca71b3ccac90880f9836769e98da3f0","grade":false,"grade_id":"cell-60a53a8850c3edc1","locked":true,"schema_version":1,"solution":false},"cell_id":"00016-1bf5d807-48be-487f-bb4f-0c6735fc1235","deepnote_cell_type":"code"},"source":"# Show a sample of encoded input\ndf_x_train = pd.DataFrame(x_train)\ndf_x_train.sample(n=10)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"8a1efd1be135109b7c8425647ba74442","grade":true,"grade_id":"cell-8bc7bddaa9fcb356","locked":true,"points":2,"schema_version":1,"solution":false},"cell_id":"00017-ec1a4a2a-02d5-4b72-912f-906253762409","deepnote_cell_type":"code"},"source":"print(f'x_train: {x_train.shape}. y_train: {y_train.shape}')\nprint(f'x_val: {x_val.shape}. y_val: {y_val.shape}')\nprint(f'x_test: {x_test.shape}. y_test: {y_test.shape}')\n# Assert shapes of prepared data\nassert_equal((7982, 10000), x_train.shape)\nassert_equal((7982, 46), y_train.shape)\nassert_equal((1000, 10000), x_val.shape)\nassert_equal((1000, 46), y_val.shape)\nassert_equal((2246, 10000), x_test.shape)\nassert_equal((2246, 46), y_test.shape)","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 3: Training a model","metadata":{"cell_id":"00018-621519ec-318e-4dd7-846e-592afb1e244b","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### Question\n\nTrain a model on the data to obtain a training accuracy > 95%. Store the training history in a variable named `history`.","metadata":{"cell_id":"00019-7f200880-7c68-4193-8fb1-08e2d7568fdc","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"11d5b1334b2f3d7aa1f581b7fcf9ddc0","grade":false,"grade_id":"cell-c7357cd3dec4e27d","locked":false,"schema_version":1,"solution":true},"cell_id":"00020-b87a7d4b-8b9b-49d9-9537-7050e88ff61e","deepnote_cell_type":"code"},"source":"# YOUR CODE HERE","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"14652663da031a2dfeca11a3398423e3","grade":true,"grade_id":"cell-cdc7a485b5d8fdfd","locked":true,"points":1,"schema_version":1,"solution":false},"cell_id":"00021-e9acbb13-b4dd-4e42-9566-47830e6dbbd9","deepnote_cell_type":"code"},"source":"# Retrieve final training accuracy\ntrain_acc = history.history['acc'][-1]\n# Assert final accuracy\nassert_true(train_acc > 0.95)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"429873aca0874d7c0a5840c12eaf8c6a","grade":false,"grade_id":"cell-9ed25aeff282a0c7","locked":true,"schema_version":1,"solution":false},"cell_id":"00022-728b5024-3ee4-4710-8c95-4fdd86da0433","deepnote_cell_type":"code"},"source":"# Evaluate model performance on test data\ntest_loss, test_acc = model.evaluate(x_test, y_test)\n\nprint('Test accuracy: {:.2f}%'.format(test_acc * 100))","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 4: Tuning the model","metadata":{"cell_id":"00023-549f2e73-9a73-448b-bc3e-09d17f922819","deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### Question\n\nIf necessary, tune your model to obtain a validation accuracy > 82%.","metadata":{"cell_id":"00024-ef55d2dd-72ba-4fe0-88ef-c8396e00eb63","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"53c46527312d5ab5d23dd42f1b1e671e","grade":false,"grade_id":"cell-a5d8dd24b58db09a","locked":false,"schema_version":1,"solution":true},"cell_id":"00025-28913831-a811-4ef4-975a-adda5a09c4fe","deepnote_cell_type":"code"},"source":"# YOUR CODE HERE","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"491fbccb2ac0417f22b3f2cca94377dd","grade":true,"grade_id":"cell-6ca80bc795d3592b","locked":true,"points":2,"schema_version":1,"solution":false},"cell_id":"00026-ce25b974-99cf-4ef1-80b2-838066f4c9c5","deepnote_cell_type":"code"},"source":"# Retrieve final validation accuracy\nval_acc = history.history['val_acc'][-1]\n# Assert final accuracy\nassert_true(val_acc > 0.82)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"2bee0f02ecc0454cdb32d86c16fb4382","grade":false,"grade_id":"cell-32e72a4e45c1abeb","locked":true,"schema_version":1,"solution":false},"cell_id":"00027-3137ff9e-ee23-425c-9adf-7f8465693327","deepnote_cell_type":"code"},"source":"# Evaluate model performance on test data\ntest_loss, test_acc = model.evaluate(x_test, y_test)\n\nprint('Test accuracy: {:.2f}%'.format(test_acc * 100))","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00028-115ca731-b9c9-45af-bc65-7955684aa1e4","deepnote_cell_type":"code"},"source":"","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"deepnote_notebook_id":"3ededf96-b826-4db7-aefc-0ae686450c6b","deepnote_execution_queue":[]}}