{"cells":[{"cell_type":"markdown","source":"## Imports","metadata":{"cell_id":"00000-a65ee01c-478d-4c46-ae9d-4cf230ef7860","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00001-4275e9ef-6690-407c-8464-c69ad1e63f89","deepnote_to_be_reexecuted":false,"source_hash":"d46d2d4f","execution_millis":50,"execution_start":1612190589943,"deepnote_cell_type":"code"},"source":"# pip install --upgrade scikit-learn","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{},"colab_type":"code","id":"mjnuJ19dJV7v","cell_id":"00002-361b8214-20c1-4331-bf05-967f7f3daeae","deepnote_to_be_reexecuted":false,"source_hash":"a4a6928a","execution_millis":1,"execution_start":1612190603951,"deepnote_cell_type":"code"},"source":"import time\nfrom IPython.display import clear_output\nimport numpy    as np\nimport pandas   as pd\nimport seaborn  as sb\nimport matplotlib.pyplot as plt\nimport sklearn  as skl\n\nfrom sklearn import pipeline      # Pipeline\nfrom sklearn import preprocessing # OrdinalEncoder, LabelEncoder\nfrom sklearn import impute\nfrom sklearn import compose\nfrom sklearn import model_selection # train_test_split\nfrom sklearn import metrics         # accuracy_score, balanced_accuracy_score, plot_confusion_matrix\nfrom sklearn import set_config\n\nset_config(display='diagram') # Useful for display the pipeline\n\nprint(\"Pandas  \", pd.__version__)\nprint(\"Sklearn \", skl.__version__) # Try to use 0.24","execution_count":15,"outputs":[{"name":"stdout","text":"Pandas   1.2.1\nSklearn  0.24.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Get the dataset\n- **CLOUD = True**: Download dataset from Kaggle. Necesary for cloud enviroments like COLAB. **Specify your [kaggle credentials](https://www.kaggle.com/docs/api)**.\n- **CLOUD = False**: Get the dataset from your local machine. **Specify the data path**.","metadata":{"cell_id":"00003-e990139a-5692-496a-beee-add3c451c395","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00004-e701137d-4c2f-4aea-8b6b-13028160920c","deepnote_to_be_reexecuted":false,"source_hash":"60c67840","execution_millis":16,"execution_start":1612190591643,"deepnote_cell_type":"code"},"source":"CLOUD = False\n\nif CLOUD:\n    import os\n    os.environ['KAGGLE_USERNAME'] = \"your_kaggle_username\"\n    os.environ['KAGGLE_KEY']      = \"your_kaggle_api_key\"  # See https://www.kaggle.com/docs/api\n    !pip install --upgrade kaggle\n    !kaggle competitions download -c titanic\n    DATA_PATH = \"./\"\n\nelse:\n    DATA_PATH = \"../../datasets/titanic/\"","execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{"cell_id":"00005-0c6e08cb-76db-40fa-af08-828a6a20d412","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"colab":{},"colab_type":"code","id":"wAy8TnVPJV8S","cell_id":"00006-f57940b7-9b52-49d7-b31e-9ca9c36e5b1a","deepnote_to_be_reexecuted":false,"source_hash":"e6b3969e","execution_millis":18,"execution_start":1612190591659,"deepnote_cell_type":"code"},"source":"df      = pd.read_csv(DATA_PATH + \"train.csv\", index_col='PassengerId')\ndf_test = pd.read_csv(DATA_PATH + \"test.csv\",  index_col='PassengerId')\n\nprint(\"Train DataFrame:\", df.shape)\nprint(\"Test DataFrame: \", df_test.shape)","execution_count":4,"outputs":[{"name":"stdout","text":"Train DataFrame: (891, 11)\nTest DataFrame:  (418, 10)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Check missings","metadata":{"cell_id":"00007-9708ab8e-318c-4178-952d-0f7c4d9ec921","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00008-c3a5228e-9831-41dc-b7f8-248a0e391036","deepnote_to_be_reexecuted":false,"source_hash":"f3dd26da","execution_millis":47,"execution_start":1612190591677,"deepnote_cell_type":"code"},"source":"df.isnull().sum()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"Survived      0\nPclass        0\nName          0\nSex           0\nAge         177\nSibSp         0\nParch         0\nTicket        0\nFare          0\nCabin       687\nEmbarked      2\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","metadata":{"cell_id":"00009-a8d807ec-7a60-4cc2-9b15-52301f7418cf","deepnote_to_be_reexecuted":false,"source_hash":"5a27af67","execution_millis":0,"execution_start":1612190591724,"deepnote_cell_type":"code"},"source":"df_test.isnull().sum()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"Pclass        0\nName          0\nSex           0\nAge          86\nSibSp         0\nParch         0\nTicket        0\nFare          1\nCabin       327\nEmbarked      0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Exercise 1:\nExtract the title (Mr, Mrs, ... ) from the \"Name\" column.\n\nTips:\n- split(',')[1] to get the 2nd part, and remove the surnamename\n- split('.')[0] to get the 1str part, and remove the name","metadata":{"cell_id":"00010-9140dc63-1e21-4dec-99a4-a81aea97c0ba","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00011-bcbfc2ab-2fe6-4a43-9c18-7eafef2ba3b9","deepnote_to_be_reexecuted":false,"source_hash":"c085b6ba","execution_millis":54,"execution_start":1612190591726,"deepnote_cell_type":"code"},"source":"df.head()","execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00011-5a060d69-b156-4e72-99f9-5e66896be210","deepnote_to_be_reexecuted":false,"source_hash":"5dfb1999","execution_millis":7,"execution_start":1612190591808,"deepnote_cell_type":"code"},"source":"# CODE HERE get_Title_from_Name funtion\ndef get_Title_from_Name(name):\n    s = name.split(',')[1].split('.')[0].strip()   \n    return s \n\ndf[\"Title\"]      = df['Name'].map(get_Title_from_Name)\ndf_test[\"Title\"] = df_test['Name'].map(get_Title_from_Name)\ndf_test.Title.value_counts()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"Mr        240\nMiss       78\nMrs        72\nMaster     21\nCol         2\nRev         2\nDona        1\nMs          1\nDr          1\nName: Title, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# Exercise 2:\nApply the title_dictionary to get a better information about the title. You have to overwrite the Title variable.","metadata":{"cell_id":"00012-2771f3fa-aa2d-403f-b0f2-e67ac3d985bd","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00013-c804d1af-191b-4fd2-8266-dedcd54238b1","deepnote_to_be_reexecuted":false,"source_hash":"258d4ea2","execution_millis":5,"execution_start":1612190591819,"deepnote_cell_type":"code"},"source":"title_dictionary = {\n    \"Capt\": \"Officer\",\n    \"Col\": \"Officer\",\n    \"Major\": \"Officer\",\n    \"Jonkheer\": \"Royalty\",\n    \"Don\": \"Royalty\",\n    \"Dona\": \"Royalty\",\n    \"Sir\" : \"Royalty\",\n    \"Dr\": \"Officer\",\n    \"Rev\": \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Mme\": \"Mrs\",\n    \"Mlle\": \"Miss\",\n    \"Ms\": \"Mrs\",\n    \"Mr\" : \"Mr\",\n    \"Mrs\" : \"Mrs\",\n    \"Miss\" : \"Miss\",\n    \"Master\" : \"Master\",\n    \"Lady\" : \"Royalty\"\n}","execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00014-8da2f89e-33f8-47a9-8522-9d85457b8981","deepnote_to_be_reexecuted":false,"source_hash":"725de662","execution_millis":3,"execution_start":1612190591836,"deepnote_cell_type":"code"},"source":"# CODE HERE\n\ndf[\"Title\"] = [title_dictionary[n] for n in df['Title']]\ndf_test[\"Title\"] = [title_dictionary[n] for n in df_test['Title']]","execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Exercise BONUS:\nTry to extract some information from the feature **Ticket**","metadata":{"cell_id":"00015-55bc35a5-4939-467b-9134-dbb648ecffd8","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00016-b1b2ee1d-a913-4103-a522-bb6aa6b71c23","deepnote_to_be_reexecuted":false,"source_hash":"b623e53d","execution_millis":10,"execution_start":1612190591841,"deepnote_cell_type":"code"},"source":"","execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Exercise BONUS:\nTry to extract some information from the feature **Cabin**","metadata":{"cell_id":"00017-225c013b-36bd-4c38-9a80-3dd18df77063","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00018-09c71e7e-466a-4b29-8fb3-33b5ce4c49f1","deepnote_to_be_reexecuted":false,"source_hash":"b623e53d","execution_start":1612190591854,"execution_millis":7,"deepnote_cell_type":"code"},"source":"","execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing\nFor X data:\n- We drop Survived because is the target variable\n- We drop Name because we have extracted the Title: Mr, Mrs, ...\n- We drop Ticket because it has no information -> see df.Ticket.nunique()\n- We drop Cabin because it has a lot of missings (77% are missings)\n\nThen, we identify **numerical** variables and **categorical** variables,","metadata":{"cell_id":"00019-1b248927-d9f0-4a21-a0d1-98445c750de3","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00020-3a0e9074-2919-42aa-a8f7-99d2de5e7d07","deepnote_to_be_reexecuted":false,"source_hash":"48bb2d72","execution_millis":7,"execution_start":1612190591868,"deepnote_cell_type":"code"},"source":"x = df.drop(columns=[\"Survived\", 'Name', 'Ticket', 'Cabin']) # X DATA (WILL BE TRAIN+VALID DATA)\ny = df[\"Survived\"] # 0 = No, 1 = Yes\n\nx_test = df_test.drop(columns=['Name', 'Ticket', 'Cabin']) # # X_TEST DATA (NEW DATA)","execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00021-ad7929db-65b6-49ac-b429-81baaeb260b3","deepnote_to_be_reexecuted":false,"source_hash":"d4ce8b83","execution_millis":25,"execution_start":1612190591910,"deepnote_cell_type":"code"},"source":"cat_vars  = ['Sex', 'Embarked', 'Title']         # x.select_dtypes(include=[object]).columns.values.tolist()\nnum_vars  = ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age'] # x.select_dtypes(exclude=[object]).columns.values.tolist()\n\nprint(\"\\nNumerical features:\\n\", num_vars)\nprint(\"\\nCategorical features:\\n\", cat_vars)","execution_count":12,"outputs":[{"name":"stdout","text":"\nNumerical features:\n ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age']\n\nCategorical features:\n ['Sex', 'Embarked', 'Title']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Exercise 3:\nCreate a **ColumnTransformer for Tree Models**. Remember:\n- Categorical: Some SimpleImputer -> Some Encoder\n- Numerical: Some SimpleImputer -> NO Encoder","metadata":{"cell_id":"00022-47dc4d70-47ad-443a-bd6a-c3cf46f7043b","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00023-382b7408-2e65-4703-a2d7-26b9b1584a7a","deepnote_to_be_reexecuted":false,"source_hash":"4d16e4cf","execution_millis":42,"execution_start":1612190591936,"deepnote_cell_type":"code"},"source":"num_preprocessing = pipeline.Pipeline(steps=[\n  # Some SimpleImputer here\n  ('imputer', impute.SimpleImputer(strategy='mean',add_indicator=False))\n])\n\ncat_preporcessing = pipeline.Pipeline(steps=[\n  # Some SimpleImputer here\n  ('imputer', impute.SimpleImputer(strategy='constant', fill_value='missing')),\n  # Some Encoder here. Remember to handle_unknown\n  ('onehot', preprocessing.OneHotEncoder(handle_unknown='ignore'))\n])\n\ntree_prepro = compose.ColumnTransformer(transformers=[\n    ('num', num_preprocessing, num_vars),\n    ('cat', cat_preporcessing, cat_vars),\n], remainder='drop') # Drop other vars not specified in num_vars or cat_vars\n\ntree_prepro","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"ColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer', SimpleImputer())]),\n                                 ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age']),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(fill_value='missing',\n                                                                strategy='constant')),\n                                                 ('onehot',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 ['Sex', 'Embarked', 'Title'])])","text/html":"<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"86dbdb53-f30d-427f-93ce-8ca30abdc73c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"86dbdb53-f30d-427f-93ce-8ca30abdc73c\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer', SimpleImputer())]),\n                                 ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age']),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(fill_value='missing',\n                                                                strategy='constant')),\n                                                 ('onehot',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 ['Sex', 'Embarked', 'Title'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"91a91914-77e4-4f90-ad98-3ed08d387be8\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"91a91914-77e4-4f90-ad98-3ed08d387be8\">num</label><div class=\"sk-toggleable__content\"><pre>['Pclass', 'SibSp', 'Parch', 'Fare', 'Age']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"504dbed3-6c33-47f3-8f75-13323954d5d6\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"504dbed3-6c33-47f3-8f75-13323954d5d6\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"94b07215-781a-457b-b597-66015807a5c4\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"94b07215-781a-457b-b597-66015807a5c4\">cat</label><div class=\"sk-toggleable__content\"><pre>['Sex', 'Embarked', 'Title']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a1e334f5-0d8b-4ed9-a7ee-bcca2c1d435d\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a1e334f5-0d8b-4ed9-a7ee-bcca2c1d435d\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value='missing', strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3d372383-5b8b-42ca-bea3-c82dcd7eb1c3\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3d372383-5b8b-42ca-bea3-c82dcd7eb1c3\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Exercise 4\n1. Complete the diccionary with some Tree Models.\n2. Then we put each model in a Pipeline where:\n   - first is the prepocessing with the column Transformer\n   - Then is the Tree model\n3. Display the fullpipeline of the LGBMClassifier","metadata":{"cell_id":"00024-9b9a155b-51a3-4201-8c71-b13c4e15630e","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00025-7ff84820-a29c-4667-b47f-a0ef8cac8ba7","deepnote_to_be_reexecuted":false,"source_hash":"657a8b57","execution_millis":100,"execution_start":1612190619045,"deepnote_cell_type":"code"},"source":"from sklearn.tree          import DecisionTreeClassifier\nfrom sklearn.ensemble      import RandomForestClassifier\nfrom sklearn.ensemble      import ExtraTreesClassifier\nfrom sklearn.ensemble      import AdaBoostClassifier\nfrom sklearn.ensemble      import GradientBoostingClassifier\nfrom sklearn.experimental  import enable_hist_gradient_boosting # Necesary for HistGradientBoostingClassifier\nfrom sklearn.ensemble      import HistGradientBoostingClassifier\nfrom xgboost               import XGBClassifier\nfrom lightgbm              import LGBMClassifier\nfrom catboost              import CatBoostClassifier","execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00026-16bf207e-af7e-4435-9b5c-761e2a9a93db","deepnote_to_be_reexecuted":false,"source_hash":"6563d84","execution_millis":2,"execution_start":1612190623224,"deepnote_cell_type":"code"},"source":"tree_classifiers = {\n  \"Decision Tree\": DecisionTreeClassifier(),\n  \"Extra Trees\": ExtraTreesClassifier(),\n  \"Random Forest\": RandomForestClassifier(),\n  \"AdaBoost\": AdaBoostClassifier(),\n  \"Skl GBM\": GradientBoostingClassifier(),\n  \"Skl HistGBM\": HistGradientBoostingClassifier(),\n  \"XGBoost\": XGBClassifier(),\n  \"LightGBM\": LGBMClassifier(),\n  \"CatBoost\": CatBoostClassifier(verbose=200)\n}\n\ntree_classifiers = {name: pipeline.make_pipeline(tree_prepro, model) for name, model in tree_classifiers.items()}","execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Exercise 5:\nDefine a simple split validation strategy with:\n- 80% for train\n- 20% for validation\n- With stratification\n- random_state=0\n\nAnd train all the models in a for loop","metadata":{"cell_id":"00027-736a9820-0d46-4542-8fad-2f53bc2025e1","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00028-14477411-13b1-4b4f-a957-d28c73c93f83","deepnote_to_be_reexecuted":false,"source_hash":"6c04e327","execution_millis":218172,"execution_start":1612190631787,"deepnote_cell_type":"code"},"source":"x_train, x_val, y_train, y_val = model_selection.train_test_split(x,y, test_size=0.2, stratify=y)\n\nfor model_name, model in tree_classifiers.items():\n    # CODE HERE\n    # TRAIN PIPELINE (PREPRO + MODEL) WITH TRAIN DATA\n    m = tree_classifiers[model_name].fit(x_train, y_train)\n    pred = m.predict(x_val) \n    # EVAL PIPELINE WITH VAL DATA (SEE ACCURACY AND BALANCED_ACCURACY)\n    print(model_name, \" has accuracy of \", metrics.accuracy_score(pred,y_val), \" and balnced accuracy \", metrics.balanced_accuracy_score(pred,y_val))","execution_count":18,"outputs":[{"name":"stdout","text":"Decision Tree  has accuracy of  0.7486033519553073  and balnced accuracy  0.7358429858429858\nExtra Trees  has accuracy of  0.8156424581005587  and balnced accuracy  0.8067176186645213\nRandom Forest  has accuracy of  0.7877094972067039  and balnced accuracy  0.7763859275053304\nAdaBoost  has accuracy of  0.8212290502793296  and balnced accuracy  0.8113306982872199\nSkl GBM  has accuracy of  0.8268156424581006  and balnced accuracy  0.8242997198879551\nSkl HistGBM  has accuracy of  0.8156424581005587  and balnced accuracy  0.8096912048524951\n/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n[14:47:26] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nXGBoost  has accuracy of  0.8100558659217877  and balnced accuracy  0.8012820512820513\nLightGBM  has accuracy of  0.8212290502793296  and balnced accuracy  0.8168935815504307\nLearning rate set to 0.008911\n0:\tlearn: 0.6873504\ttotal: 48.1ms\tremaining: 48s\n200:\tlearn: 0.3787116\ttotal: 377ms\tremaining: 1.5s\n400:\tlearn: 0.3411506\ttotal: 753ms\tremaining: 1.13s\n600:\tlearn: 0.3166280\ttotal: 1.09s\tremaining: 722ms\n800:\tlearn: 0.2955592\ttotal: 1.46s\tremaining: 362ms\n999:\tlearn: 0.2753624\ttotal: 1.84s\tremaining: 0us\nCatBoost  has accuracy of  0.8547486033519553  and balnced accuracy  0.8516694033935412\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Exercise 6:\nDefine a 10 Fold cross validation strategy with:\n- With stratification\n- shuffle=True\n- random_state=0\n\nAnd train all the models in a for loop.\n\nTip you can use **[cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)** for both training and predict with ","metadata":{"cell_id":"00029-07e2ca3f-0cad-4484-a88f-d398dcf620be","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00030-ee2392bb-7214-4f63-a59f-df2e2feff9df","deepnote_to_be_reexecuted":false,"source_hash":"1dfc965","execution_millis":34829,"execution_start":1612192176317,"deepnote_cell_type":"code"},"source":"skf = model_selection.StratifiedKFold(n_splits=10)\n\nfor model_name, model in tree_classifiers.items():\n    # CODE HERE\n    # TRAIN PIPELINE (PREPRO + MODEL) WITH TRAIN DATA\n    pred = model_selection.cross_val_predict(tree_classifiers[model_name], x_train, y_train, cv=skf)\n    # EVAL PIPELINE WITH VAL DATA (SEE ACCURACY AND BALANCED_ACCURACY)\n    print(model_name, \" has accuracy of \",model.score(x_val,y_val))\n    ","execution_count":27,"outputs":[{"name":"stdout","text":"Decision Tree  has accuracy of  0.7486033519553073\nExtra Trees  has accuracy of  0.8156424581005587\nRandom Forest  has accuracy of  0.7877094972067039\nAdaBoost  has accuracy of  0.8212290502793296\nSkl GBM  has accuracy of  0.8268156424581006\nSkl HistGBM  has accuracy of  0.8156424581005587\n[15:09:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n[15:09:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n[15:09:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[15:09:49] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n[15:09:50] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n[15:09:50] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n[15:09:50] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n[15:09:50] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n[15:09:50] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n/usr/local/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n[15:09:51] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nXGBoost  has accuracy of  0.8100558659217877\nLightGBM  has accuracy of  0.8212290502793296\nLearning rate set to 0.008515\n0:\tlearn: 0.6873069\ttotal: 1.02ms\tremaining: 1.02s\n200:\tlearn: 0.3752561\ttotal: 369ms\tremaining: 1.47s\n400:\tlearn: 0.3357281\ttotal: 688ms\tremaining: 1.03s\n600:\tlearn: 0.3109789\ttotal: 1.05s\tremaining: 695ms\n800:\tlearn: 0.2906578\ttotal: 1.36s\tremaining: 339ms\n999:\tlearn: 0.2711134\ttotal: 1.73s\tremaining: 0us\nLearning rate set to 0.008515\n0:\tlearn: 0.6875893\ttotal: 1.03ms\tremaining: 1.03s\n200:\tlearn: 0.3775901\ttotal: 286ms\tremaining: 1.14s\n400:\tlearn: 0.3366131\ttotal: 657ms\tremaining: 981ms\n600:\tlearn: 0.3118529\ttotal: 982ms\tremaining: 652ms\n800:\tlearn: 0.2917080\ttotal: 1.35s\tremaining: 336ms\n999:\tlearn: 0.2699077\ttotal: 1.72s\tremaining: 0us\nLearning rate set to 0.00852\n0:\tlearn: 0.6878848\ttotal: 1.02ms\tremaining: 1.02s\n200:\tlearn: 0.3949559\ttotal: 287ms\tremaining: 1.14s\n400:\tlearn: 0.3543854\ttotal: 660ms\tremaining: 986ms\n600:\tlearn: 0.3322086\ttotal: 981ms\tremaining: 651ms\n800:\tlearn: 0.3113689\ttotal: 1.35s\tremaining: 337ms\n999:\tlearn: 0.2904379\ttotal: 1.67s\tremaining: 0us\nLearning rate set to 0.00852\n0:\tlearn: 0.6877646\ttotal: 1.02ms\tremaining: 1.02s\n200:\tlearn: 0.3795886\ttotal: 301ms\tremaining: 1.2s\n400:\tlearn: 0.3395087\ttotal: 666ms\tremaining: 995ms\n600:\tlearn: 0.3151123\ttotal: 988ms\tremaining: 656ms\n800:\tlearn: 0.2932635\ttotal: 1.35s\tremaining: 337ms\n999:\tlearn: 0.2726613\ttotal: 1.67s\tremaining: 0us\nLearning rate set to 0.00852\n0:\tlearn: 0.6873819\ttotal: 1.01ms\tremaining: 1.01s\n200:\tlearn: 0.3834324\ttotal: 332ms\tremaining: 1.32s\n400:\tlearn: 0.3447892\ttotal: 647ms\tremaining: 967ms\n600:\tlearn: 0.3226089\ttotal: 1.02s\tremaining: 675ms\n800:\tlearn: 0.3003551\ttotal: 1.33s\tremaining: 332ms\n999:\tlearn: 0.2781237\ttotal: 1.7s\tremaining: 0us\nLearning rate set to 0.00852\n0:\tlearn: 0.6875021\ttotal: 1.05ms\tremaining: 1.05s\n200:\tlearn: 0.3696729\ttotal: 287ms\tremaining: 1.14s\n400:\tlearn: 0.3295665\ttotal: 651ms\tremaining: 972ms\n600:\tlearn: 0.3041244\ttotal: 974ms\tremaining: 646ms\n800:\tlearn: 0.2833824\ttotal: 1.34s\tremaining: 334ms\n999:\tlearn: 0.2639677\ttotal: 1.67s\tremaining: 0us\nLearning rate set to 0.00852\n0:\tlearn: 0.6877198\ttotal: 1.32ms\tremaining: 1.32s\n200:\tlearn: 0.3868022\ttotal: 297ms\tremaining: 1.18s\n400:\tlearn: 0.3481580\ttotal: 664ms\tremaining: 991ms\n600:\tlearn: 0.3249849\ttotal: 991ms\tremaining: 658ms\n800:\tlearn: 0.3037393\ttotal: 1.34s\tremaining: 334ms\n999:\tlearn: 0.2830851\ttotal: 1.66s\tremaining: 0us\nLearning rate set to 0.00852\n0:\tlearn: 0.6874873\ttotal: 989us\tremaining: 988ms\n200:\tlearn: 0.3707833\ttotal: 339ms\tremaining: 1.35s\n400:\tlearn: 0.3300508\ttotal: 655ms\tremaining: 978ms\n600:\tlearn: 0.3049905\ttotal: 1.02s\tremaining: 680ms\n800:\tlearn: 0.2835018\ttotal: 1.34s\tremaining: 334ms\n999:\tlearn: 0.2601565\ttotal: 1.73s\tremaining: 0us\nLearning rate set to 0.00852\n0:\tlearn: 0.6875964\ttotal: 964us\tremaining: 963ms\n200:\tlearn: 0.3758282\ttotal: 333ms\tremaining: 1.32s\n400:\tlearn: 0.3368565\ttotal: 649ms\tremaining: 970ms\n600:\tlearn: 0.3133891\ttotal: 1.01s\tremaining: 673ms\n800:\tlearn: 0.2929783\ttotal: 1.33s\tremaining: 332ms\n999:\tlearn: 0.2730346\ttotal: 1.71s\tremaining: 0us\nLearning rate set to 0.00852\n0:\tlearn: 0.6871921\ttotal: 1.01ms\tremaining: 1.01s\n200:\tlearn: 0.3668175\ttotal: 332ms\tremaining: 1.32s\n400:\tlearn: 0.3249082\ttotal: 652ms\tremaining: 974ms\n600:\tlearn: 0.3009285\ttotal: 1.02s\tremaining: 677ms\n800:\tlearn: 0.2782235\ttotal: 1.34s\tremaining: 333ms\n999:\tlearn: 0.2574603\ttotal: 1.71s\tremaining: 0us\nCatBoost  has accuracy of  0.8994413407821229\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Exercise 7\nTrain **with all data** the best model","metadata":{"cell_id":"00031-5c0c144a-d6a8-4e39-a811-2fc01b27cb0f","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"colab":{},"colab_type":"code","id":"monuuQhHL7B_","cell_id":"00032-54f4d418-97c5-48cb-9efd-07c688c4fa33","deepnote_to_be_reexecuted":false,"source_hash":"4164a663","execution_millis":1914,"execution_start":1612191507043,"deepnote_cell_type":"code"},"source":"best_model = 'CatBoost' #CatBoostClassifier(verbose=200)# Select your best model\n# Train with all data your best model\nx_p = tree_classifiers[best_model].fit(x,y)\n","execution_count":21,"outputs":[{"name":"stdout","text":"Learning rate set to 0.009807\n0:\tlearn: 0.6861863\ttotal: 1.19ms\tremaining: 1.19s\n200:\tlearn: 0.3779043\ttotal: 342ms\tremaining: 1.36s\n400:\tlearn: 0.3454862\ttotal: 678ms\tremaining: 1.01s\n600:\tlearn: 0.3227697\ttotal: 1.07s\tremaining: 708ms\n800:\tlearn: 0.3009774\ttotal: 1.45s\tremaining: 360ms\n999:\tlearn: 0.2789732\ttotal: 1.84s\tremaining: 0us\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Exercise 8\nWith your best model, generate the predicitions for test data (x_test)","metadata":{"cell_id":"00033-486cf349-dc69-4cd6-9383-66b4ff6b77e6","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00034-e1162f4d-1af7-4200-9e8a-82ffe3395e8a","deepnote_to_be_reexecuted":false,"source_hash":"fa0931e4","execution_millis":0,"execution_start":1612191519261,"deepnote_cell_type":"code"},"source":"\ntest_pred = x_p.predict(x_test)# Get the predictions for x_test","execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Exercise 9\n\nSubmit to kaggle using the kaggle API. And send us your score. You can try to improve it.","metadata":{"cell_id":"00035-01ef7665-02f3-4232-858f-e67c02749174","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00036-8b755506-8c06-4f8d-9140-bf6d8045e78e","deepnote_to_be_reexecuted":false,"source_hash":"82f8bb8f","execution_start":1612191525253,"execution_millis":4,"deepnote_cell_type":"code"},"source":"sub = pd.DataFrame(test_pred, index=x_test.index, columns=[\"Survived\"])\nsub.head()","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"application/vnd.deepnote.dataframe.v2+json":{"row_count":5,"column_count":1,"columns":[{"name":"Survived","dtype":"int64","stats":{"unique_count":2,"nan_count":0,"min":0,"max":1,"histogram":[{"bin_start":0,"bin_end":0.1,"count":4},{"bin_start":0.1,"bin_end":0.2,"count":0},{"bin_start":0.2,"bin_end":0.30000000000000004,"count":0},{"bin_start":0.30000000000000004,"bin_end":0.4,"count":0},{"bin_start":0.4,"bin_end":0.5,"count":0},{"bin_start":0.5,"bin_end":0.6000000000000001,"count":0},{"bin_start":0.6000000000000001,"bin_end":0.7000000000000001,"count":0},{"bin_start":0.7000000000000001,"bin_end":0.8,"count":0},{"bin_start":0.8,"bin_end":0.9,"count":0},{"bin_start":0.9,"bin_end":1,"count":1}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows_top":[{"Survived":0,"_deepnote_index_column":892},{"Survived":0,"_deepnote_index_column":893},{"Survived":0,"_deepnote_index_column":894},{"Survived":0,"_deepnote_index_column":895},{"Survived":1,"_deepnote_index_column":896}],"rows_bottom":null},"text/plain":"             Survived\nPassengerId          \n892                 0\n893                 0\n894                 0\n895                 0\n896                 1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>892</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>893</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>894</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","metadata":{"cell_id":"00037-5d74695a-5f5d-4588-b6e9-49d307a23b43","deepnote_to_be_reexecuted":false,"source_hash":"d25356f7","execution_start":1612191531349,"execution_millis":7,"deepnote_cell_type":"code"},"source":"sub.to_csv(\"sub.csv\")","execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00038-038235c2-8728-4bf0-95fe-532870644ea8","deepnote_to_be_reexecuted":true,"source_hash":"925aa86d","deepnote_cell_type":"code"},"source":"#!kaggle competitions submit -c titanic -f sub.csv -m \"My submission message\"","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exercise BONUS\n\nKnowing how to export your models is very important for putting models in production. Try to\n- Export and Load the ColumTransformer in pickle\n- Export and Load the ColumTransformer in joblib\n- Export and load the Pipeline","metadata":{"cell_id":"00039-a3437e52-533e-4aac-9d7f-58d90e764e23","deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":4,"metadata":{"anaconda-cloud":{},"colab":{"collapsed_sections":[],"name":"Titanic LogReg.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"},"name":"seminar13_optional_practice_trees_titanic.ipynb","deepnote_notebook_id":"9912e28c-fb3f-4697-99f8-460ff2e5737e","deepnote_execution_queue":[]}}